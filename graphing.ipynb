{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e9f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_network_results(path):\n",
    "    '''\n",
    "    Returns the results of a network training.\n",
    "    Args:\n",
    "        path: Path to the results file.\n",
    "    Returns:\n",
    "        List of tuples of (epoch, loss, fake_correct, fake_incorrect, real_correct, real_incorrect)\n",
    "    '''\n",
    "    results = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.split(',')\n",
    "            epoch = int(line[0].split(': ')[1])\n",
    "            loss = float(line[1].split(': ')[1])\n",
    "            fake_correct = int(line[2].split(': ')[1])\n",
    "            fake_incorrect = int(line[3].split(': ')[1])\n",
    "            real_correct = int(line[4].split(': ')[1])\n",
    "            real_incorrect = int(line[5].split(': ')[1])\n",
    "            results.append((epoch, loss, fake_correct, fake_incorrect, real_correct, real_incorrect))\n",
    "    return results\n",
    "\n",
    "def get_accuracy(results):\n",
    "    '''\n",
    "    Returns the accuracy of a network.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "    Returns:\n",
    "        List of tuples of (epoch, accuracy)\n",
    "    '''\n",
    "    accuracies = []\n",
    "    for result in results:\n",
    "        epoch = result[0]\n",
    "        fake_correct = result[2]\n",
    "        fake_incorrect = result[3]\n",
    "        real_correct = result[4]\n",
    "        real_incorrect = result[5]\n",
    "        accuracy = (fake_correct + real_correct)/(fake_correct + fake_incorrect + real_correct + real_incorrect)\n",
    "        accuracies.append((epoch, accuracy))\n",
    "    return accuracies\n",
    "\n",
    "def get_f1_real(results):\n",
    "    '''\n",
    "    Returns the F1 score of a network.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "    Returns:\n",
    "        List of tuples of (epoch, f1)\n",
    "    '''\n",
    "    f1s = []\n",
    "    for result in results:\n",
    "        epoch = result[0]\n",
    "        fake_correct = result[2]\n",
    "        fake_incorrect = result[3]\n",
    "        real_correct = result[4]\n",
    "        real_incorrect = result[5]\n",
    "        precision = real_correct/(real_correct + fake_incorrect)\n",
    "        recall = real_correct/(real_correct + real_incorrect)\n",
    "        f1 = 2 * (precision * recall)/(precision + recall)\n",
    "        f1s.append((epoch, f1))\n",
    "    return f1s\n",
    "\n",
    "def get_f1_fake(results):\n",
    "    '''\n",
    "    Returns the F1 score of a network for fake images.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "    Returns:\n",
    "        List of tuples of (epoch, f1)\n",
    "    '''\n",
    "    f1s = []\n",
    "    for result in results:\n",
    "        epoch = result[0]\n",
    "        fake_correct = result[2]\n",
    "        fake_incorrect = result[3]\n",
    "        real_correct = result[4]\n",
    "        real_incorrect = result[5]\n",
    "        precision = fake_correct/(fake_correct + real_incorrect)\n",
    "        recall = fake_correct/(fake_correct + fake_incorrect)\n",
    "        f1 = 2 * (precision * recall)/(precision + recall)\n",
    "        f1s.append((epoch, f1))\n",
    "    return f1s\n",
    "\n",
    "def plot_accuracy_train_val(results_train, results_val, name):\n",
    "    '''\n",
    "    Plots the accuracy of a network.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "        name: Name of the network\n",
    "    '''\n",
    "    accuracies_train = get_accuracy(results_train)\n",
    "    accuracies_val = get_accuracy(results_val)\n",
    "    epochs = [accuracy[0] for accuracy in accuracies_train]\n",
    "    accuracy_train = [accuracy[1] for accuracy in accuracies_train]\n",
    "    accuracy_val = [accuracy[1] for accuracy in accuracies_val]\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, accuracy_train, label='train')\n",
    "    plt.plot(epochs, accuracy_val, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Accuracy of {name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_f1_real_train_val(results_train, results_val, name):\n",
    "    '''\n",
    "    Plots the F1 score of a network.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "        name: Name of the network\n",
    "    '''\n",
    "    f1s_train = get_f1_real(results_train)\n",
    "    f1s_val = get_f1_real(results_val)\n",
    "    epochs = [f1[0] for f1 in f1s_train]\n",
    "    f1_train = [f1[1] for f1 in f1s_train]\n",
    "    f1_val = [f1[1] for f1 in f1s_val]\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, f1_train, label='train')\n",
    "    plt.plot(epochs, f1_val, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.title(f'F1 of {name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_f1_fake_train_val(results_train, results_val, name):\n",
    "    '''\n",
    "    Plots the F1 score of a network for fake images.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "        name: Name of the network\n",
    "    '''\n",
    "    f1s_train = get_f1_fake(results_train)\n",
    "    f1s_val = get_f1_fake(results_val)\n",
    "    epochs = [f1[0] for f1 in f1s_train]\n",
    "    f1_train = [f1[1] for f1 in f1s_train]\n",
    "    f1_val = [f1[1] for f1 in f1s_val]\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, f1_train, label='train')\n",
    "    plt.plot(epochs, f1_val, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1')\n",
    "    plt.title(f'F1 of {name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_train_val(results_train, results_val, name):\n",
    "    '''\n",
    "    Plots the loss of a network.\n",
    "    Args:\n",
    "        results: Results of a network training\n",
    "        name: Name of the network\n",
    "    '''\n",
    "    losses_train = [result[1] for result in results_train]\n",
    "    losses_val = [result[1] for result in results_val]\n",
    "    epochs = [result[0] for result in results_train]\n",
    "    plt.xticks(epochs)\n",
    "    plt.plot(epochs, losses_train, label='train')\n",
    "    plt.plot(epochs, losses_val, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'Loss of {name}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def get_predictions(target_results_file):\n",
    "    '''\n",
    "    Returns the predictions of a network.\n",
    "    Args:\n",
    "        target_results_file: Path to the results file of the target network\n",
    "    Returns:\n",
    "        List of tuples of (epoch, prediction)\n",
    "    '''\n",
    "    predictions = []\n",
    "    with open(target_results_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if 'prediction' in line:\n",
    "                prediction = line[line.find('[[')+2:line.find(']]')]\n",
    "                prediction_vals = prediction.split(', ')\n",
    "                predictions.append(float(prediction_vals[0]), float(prediction_vals[1]))\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def get_prediction_change(target_results_file):\n",
    "    predictions = get_predictions(target_results_file)\n",
    "    return predictions[-2][0]/predictions[-1][0]\n",
    "\n",
    "def plot_prediction_change(poison_numbers):\n",
    "    poison_predictions = []\n",
    "    experiment_path = 'results_for_diss/attack_xception_full_baseline'\n",
    "    for poison_number in poison_numbers:\n",
    "        experiment_n_path = os.path.join(experiment_path, f'{poison_number}_poisons')\n",
    "        for folder in os.listdir(experiment_n_path):\n",
    "            if True:\n",
    "                poison_predictions.append(get_prediction_change(f'poison_{poison_number}_results.txt'))\n",
    "\n",
    "def extract_target_results(file):\n",
    "    predictions_clean = []\n",
    "    predictions_poisoned = []\n",
    "    poison_line = True  # Switch between reading poisoned, clean\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if len(line) < 10:\n",
    "                continue\n",
    "            prediction = line[line.find('[[')+2:line.find(']]')]\n",
    "            prediction_vals = prediction.split(', ')\n",
    "            if poison_line:\n",
    "                predictions_poisoned.append((float(prediction_vals[0]), float(prediction_vals[1])))\n",
    "            else:\n",
    "                predictions_clean.append((float(prediction_vals[0]), float(prediction_vals[1])))\n",
    "            poison_line = not poison_line\n",
    "    return predictions_clean, predictions_poisoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43bd61ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6490974231776216e-08\n",
      "0.010902330390519367\n",
      "4.077048754790735e-06\n",
      "0.05154639175257732\n",
      "1.5952016334864727\n",
      "2.6096524460550156e-05\n",
      "0.9114590550090066\n",
      "70.9870848708487\n",
      "AVG 9.194528058943934\n",
      "STD ERROR 8.829970929413259\n",
      "######\n",
      "-4.3541999281949995e-05\n",
      "-2.4871849999999998e-05\n",
      "-6.549073299000001e-08\n",
      "-0.046\n",
      "0.00055968\n",
      "-3.035420784e-05\n",
      "-1.9169999999999994e-05\n",
      "1.213856e-05\n",
      "AVG -0.005693273123481867\n",
      "STD ERROR 0.005758550043141281\n"
     ]
    }
   ],
   "source": [
    "predictions_clean, predictions_poisoned = extract_target_results(\"results_for_diss/attack_xception_full_baseline/20_poisons/tmp.txt\")\n",
    "x = []\n",
    "for i in range(len(predictions_clean)):\n",
    "    print(predictions_poisoned[i][0]/predictions_clean[i][0])\n",
    "    x.append(predictions_poisoned[i][0]/predictions_clean[i][0])\n",
    "print('AVG',np.average(x))\n",
    "print('STD ERROR', np.std(x, ddof=1) / np.sqrt(np.size(x)))\n",
    "print('######')\n",
    "x = []\n",
    "for i in range(len(predictions_clean)):\n",
    "    print(predictions_poisoned[i][0]-predictions_clean[i][0])\n",
    "    x.append(predictions_poisoned[i][0]-predictions_clean[i][0])\n",
    "print('AVG',np.average(x))\n",
    "print('STD ERROR', np.std(x, ddof=1) / np.sqrt(np.size(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ce992bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004418387096774194\n",
      "2.735283657582423\n",
      "24002.460299709237\n",
      "0.22306955036046172\n",
      "5.864066351746834\n",
      "10.544847952029937\n",
      "1.4233591731266151e-07\n",
      "1.9012366350132755e-07\n",
      "AVG 3002.7285011740155\n",
      "STD ERROR 2999.9619817163793\n",
      "######\n",
      "-0.0030986303\n",
      "0.000131741\n",
      "0.000858484232\n",
      "-5.5932e-06\n",
      "0.00040055099999999997\n",
      "4.2341899999999994e-09\n",
      "-0.00019349997245799998\n",
      "-8.361398410299999e-08\n",
      "AVG -0.00023837832753151287\n",
      "STD ERROR 0.0004246675468884804\n"
     ]
    }
   ],
   "source": [
    "predictions_clean, predictions_poisoned = extract_target_results(\"results_for_diss/attack_xception_full_baseline/50_poisons/tmp.txt\")\n",
    "x = []\n",
    "for i in range(len(predictions_clean)):\n",
    "    print(predictions_poisoned[i][0]/predictions_clean[i][0])\n",
    "    x.append(predictions_poisoned[i][0]/predictions_clean[i][0])\n",
    "print('AVG',np.average(x))\n",
    "print('STD ERROR', np.std(x, ddof=1) / np.sqrt(np.size(x)))\n",
    "print('######')\n",
    "x = []\n",
    "for i in range(len(predictions_clean)):\n",
    "    print(predictions_poisoned[i][0]-predictions_clean[i][0])\n",
    "    x.append(predictions_poisoned[i][0]-predictions_clean[i][0])\n",
    "print('AVG',np.average(x))\n",
    "print('STD ERROR', np.std(x, ddof=1) / np.sqrt(np.size(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15ac6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
